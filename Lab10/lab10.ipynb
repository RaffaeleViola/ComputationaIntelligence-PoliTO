{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self._board = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "\n",
    "    def reset(self):\n",
    "        self._board = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "\n",
    "    def add_x(self, pos: tuple[int]):\n",
    "        assert self._board[pos[0]][pos[1]] == 0\n",
    "        self._board[pos[0]][pos[1]] = 1\n",
    "\n",
    "    def add_o(self, pos: tuple[int]):\n",
    "        assert self._board[pos[0]][pos[1]] == 0\n",
    "        self._board[pos[0]][pos[1]] = -1\n",
    "\n",
    "    def check_pos(self, player, pos):\n",
    "        target = 3 if player == \"X\" else -3\n",
    "        center = (1, 1)\n",
    "        right_diag = {(0, 0), (2, 2)}\n",
    "        left_diag = {(0, 2), (2, 0)}\n",
    "        # checking row and column\n",
    "        if self._board[pos[0], :].sum() == target or self._board[:, pos[1]].sum() == target:\n",
    "            return True\n",
    "        # check right_diag\n",
    "        if pos in right_diag or pos == center:\n",
    "            if sum([self._board[dx, dy] for dx, dy in [(0,0), (1, 1), (2, 2)]]) == target:\n",
    "                return True\n",
    "        # check left_diag\n",
    "        if pos in right_diag or pos == center:\n",
    "            if sum([self._board[dx, dy] for dx, dy in [(0,2), (1, 1), (2, 0)]]) == target:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def check(self):\n",
    "        rows = self._board.sum(axis = 0)\n",
    "        cols = self._board.sum(axis = 1)\n",
    "        if(np.any((rows == 3)) or  np.any((cols == 3))\n",
    "                or sum([self._board[dx, dy] for dx, dy in [(0,0), (1, 1), (2, 2)]]) == 3\n",
    "                or sum([self._board[dx, dy] for dx, dy in [(0,2), (1, 1), (2, 0)]]) == 3):\n",
    "            return 1\n",
    "        if(np.any((rows == -3)) or  np.any((cols == -3))\n",
    "                or sum([self._board[dx, dy] for dx, dy in [(0,0), (1, 1), (2, 2)]]) == -3\n",
    "                or sum([self._board[dx, dy] for dx, dy in [(0,2), (1, 1), (2, 0)]]) == -3):\n",
    "            return -1\n",
    "        return 0\n",
    "\n",
    "    def copy(self):\n",
    "        bd_copy = self._board.copy()\n",
    "        new_game = TicTacToe()\n",
    "        new_game._board = bd_copy\n",
    "        return new_game\n",
    "\n",
    "    def next_moves(self):\n",
    "        return [(i, j) for j in range(3) for i in range(3) if self._board[i, j] == 0]\n",
    "\n",
    "    def __str__(self):\n",
    "        mapping = {0: \"_\", 1: \"X\", -1: \"O\"}\n",
    "        pretty = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                pretty[i][j] = mapping[self._board[i, j]]\n",
    "        return \"\\n\".join([\"|\".join(el) for el in pretty])\n",
    "\n",
    "    def new_state(self, move: tuple[int], player):\n",
    "        val = 1 if player == \"X\" else -1\n",
    "        # always player O\n",
    "        board_copy = self._board.copy()\n",
    "        board_copy[move[0], move[1]] = val\n",
    "        return tuple([tuple(row) for row in list(board_copy)])\n",
    "\n",
    "    def get_state(self):\n",
    "         return tuple([tuple(row) for row in list(self._board)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2]])\n",
    "print(board[1, :].sum())\n",
    "print(board.sum(axis = 0))\n",
    "print(board.sum(axis=1))\n",
    "\n",
    "game = TicTacToe()\n",
    "print(game)\n",
    "game.add_o((0, 0))\n",
    "game.add_x((1, 1))\n",
    "game.add_o((0, 1))\n",
    "# game.add_o((0, 1))\n",
    "print(game.new_state((0, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def game():\n",
    "    inst = TicTacToe()\n",
    "    print(inst)\n",
    "    player = 0\n",
    "    while not inst.check():\n",
    "        move = input(f\"Board:\\n{inst}\\n Player {player} enter move in the form <x-y>\")\n",
    "        xy = move.split(\"-\")\n",
    "        x, y = int(xy[0]), int(xy[1])\n",
    "        if player == 0:\n",
    "            inst.add_x((x, y))\n",
    "        else:\n",
    "            inst.add_o((x, y))\n",
    "        print(inst)\n",
    "        print()\n",
    "        player = 1 - player\n",
    "\n",
    "    print(f\"Player {1 - player} won!\")\n",
    "\n",
    "game()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reiforcement Learning Strategy\n",
    "\n",
    "The idea is to use a *Model-Free* Approach\n",
    "\n",
    "Reward = 1 for game won, 0 for draw, -1 for game lost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BackPropagation Strategy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 30_000\n",
    "learning_rate = 0.7\n",
    "\n",
    "# Environment parameters\n",
    "gamma = 0.95\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.005"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [],
   "source": [
    "Qtable = dict() # {state1: {action1: value, ..., action_n: value} ,..., state_n:{...} }\n",
    "default = 0.0\n",
    "disps = [disp for disp in list(itertools.product([0, 1, -1], repeat = 9)) if -1 <= sum(disp) <= 0] # filter valid states\n",
    "disps = [tuple([disp[ind:ind+3] for ind in range(0, 9, 3)]) for disp in disps]\n",
    "for disp in disps:\n",
    "    next_moves = [(i, j) for j in range(3) for i in range(3) if disp[i][j] == 0]\n",
    "    Qtable[disp] = {mv: default for mv in next_moves}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "outputs": [],
   "source": [
    "def backpropagation(Qtable: dict, states: list, actions: list, reward):\n",
    "    next_state = None\n",
    "    for act, state in zip(reversed(actions), reversed(states)):\n",
    "        fut_max = max(Qtable[next_state].values()) if next_state else default\n",
    "        Qtable[state][act] = Qtable[state][act] + learning_rate * (reward + gamma * fut_max - Qtable[state][act])\n",
    "        next_state = state\n",
    "    return Qtable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qtable: dict, state: TicTacToe, epsilon: float):\n",
    "  random_int = random.uniform(0,1)\n",
    "  actions = state.next_moves()\n",
    "  if random_int > epsilon:\n",
    "    return max(actions, key= lambda act: Qtable[state.get_state()][act])\n",
    "  else:\n",
    "    action = actions[random.randint(0, len(actions) - 1)]\n",
    "  return action"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:09<00:00, 3030.47it/s]\n"
     ]
    }
   ],
   "source": [
    "env = TicTacToe()\n",
    "for episode in tqdm(range(n_training_episodes)):\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "    # player = 0 # random.randint(0,1)\n",
    "    for n in [0, 1]:\n",
    "        # Reset the environment\n",
    "        env.reset()\n",
    "        player = n\n",
    "        done = 0\n",
    "        steps = 0\n",
    "        # simulating game\n",
    "        state_action = env.get_state()\n",
    "        state_history = [state_action] if n == 1 else []\n",
    "        actions_history = []\n",
    "        while done == 0 and steps <9:\n",
    "            actions = env.next_moves()\n",
    "            if player == 1:\n",
    "                action = epsilon_greedy_policy(Qtable, env, epsilon)\n",
    "                env.add_x(action)\n",
    "                actions_history.append(action)\n",
    "            else:\n",
    "                action = actions[random.randint(0, len(actions) - 1)]\n",
    "                env.add_o(action)\n",
    "                state_history.append(env.get_state())\n",
    "            done = env.check()\n",
    "            player = 1 - player\n",
    "            steps += 1\n",
    "        # updating states\n",
    "        reward = done if done != 0 else 0.05 # +1 win -1 lose 0.1 draw\n",
    "        if len(state_history) != len(actions_history):\n",
    "            # print(state_history)\n",
    "            # print(actions_history)\n",
    "            state_history.pop()\n",
    "        Qtable = backpropagation(Qtable, state_history, actions_history, reward)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 0.7, (2, 1): 0.0, (2, 2): 0.0}\n"
     ]
    }
   ],
   "source": [
    "# print(Qtable.values())\n",
    "table = ((0, 1, -1), (1, -1, -1), (1, 0, 0))\n",
    "print(Qtable[table])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, qtable: dict, letter):\n",
    "        self._name = name\n",
    "        self._QTable = qtable\n",
    "        self._letter = letter\n",
    "\n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "\n",
    "    def move(self, game_inst: TicTacToe):\n",
    "        acts = game_inst.next_moves()\n",
    "        if self._letter == \"X\":\n",
    "            best_move = max(acts, key=lambda act: Qtable[game_inst.get_state()][act])\n",
    "        else:\n",
    "            # Tha agent learned to play with +1 strategy => we need to invert the state to properly query the QTable\n",
    "            def invert_state(state):\n",
    "                brd = []\n",
    "                for i in range(3):\n",
    "                    brd.append([])\n",
    "                    for el in state[i]:\n",
    "                        brd[i].append(-el)\n",
    "                brd = tuple([tuple(row) for row in brd])\n",
    "                return brd\n",
    "            best_move = max(acts, key=lambda act: Qtable[invert_state(game_inst.get_state())][act])\n",
    "        if self._letter == \"X\":\n",
    "            game_inst.add_x(best_move)\n",
    "        else:\n",
    "            game_inst.add_o(best_move)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def game_again_agent():\n",
    "    inst = TicTacToe()\n",
    "    print(inst)\n",
    "    player = 0\n",
    "    agent = Player(\"Agent\", Qtable, \"X\")\n",
    "    steps = 0\n",
    "    while inst.check() == 0 and steps < 9:\n",
    "        if player == 0:\n",
    "            move = input(f\"Board:\\n{inst}\\n Player {player} enter move in the form <x-y>\")\n",
    "            xy = move.split(\"-\")\n",
    "            x, y = int(xy[0]), int(xy[1])\n",
    "            inst.add_o((x, y))\n",
    "        else:\n",
    "            agent.move(inst)\n",
    "        print(inst)\n",
    "        print()\n",
    "        player = 1 - player\n",
    "        steps += 1\n",
    "    if inst.check() != 0:\n",
    "        print(f\"Player {1 - player} won!\")\n",
    "    else:\n",
    "        print(f\"It's a draw guys!\")\n",
    "\n",
    "game_again_agent()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning Rate against Random: 80.31\n",
      "Drawing Rate against Random: 18.68\n"
     ]
    }
   ],
   "source": [
    "def proof():\n",
    "    winning = 0\n",
    "    drawing = 0\n",
    "    agent0 = Player(\"Agent2\", Qtable, \"X\")\n",
    "    for i in range(10_000):\n",
    "        inst = TicTacToe()\n",
    "        player = 1\n",
    "        steps = 0\n",
    "        history = []\n",
    "        while inst.check() == 0 and steps < 9:\n",
    "            if player == 0:\n",
    "                agent0.move(inst)\n",
    "            else:\n",
    "                # # add randomness otherwise it is performed the same strategy evertime\n",
    "                # if steps == 0:\n",
    "                #     act = inst.next_moves()[random.randint(0, 8)]\n",
    "                #     inst.add_x(act)\n",
    "                # else:\n",
    "                #     agent1.move(inst)\n",
    "                act = inst.next_moves()[random.randint(0, len(inst.next_moves()) - 1)]\n",
    "                inst.add_o(act)\n",
    "            history.append(f\"{inst}\")\n",
    "            player = 1 - player\n",
    "            steps += 1\n",
    "        if inst.check() == 1:\n",
    "            winning += 1\n",
    "        elif inst.check() == 0:\n",
    "            drawing += 1\n",
    "    win_rate = winning * 100 / 10_000\n",
    "    draw_rate = drawing * 100 / 10_000\n",
    "    print(f\"Winning Rate against Random: {win_rate}\")\n",
    "    print(f\"Drawing Rate against Random: {draw_rate}\")\n",
    "\n",
    "proof()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MinMax Strategy as benchmark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "outputs": [],
   "source": [
    "def minmax(game: TicTacToe, plyr, to_maximize):\n",
    "    over = game.check()\n",
    "    next_actions = game.next_moves()\n",
    "    if over != 0 or not next_actions:\n",
    "        if to_maximize == \"O\":\n",
    "            over = -over\n",
    "        return None, over\n",
    "    scores = []\n",
    "    for i, move in enumerate(next_actions):\n",
    "        new_g = game.copy()\n",
    "        if plyr == \"X\":\n",
    "            new_g.add_x(move)\n",
    "            scores.append((i, minmax(new_g, \"O\", to_maximize)[1]))\n",
    "        else:\n",
    "            new_g.add_o(move)\n",
    "            scores.append((i, minmax(new_g, \"X\", to_maximize)[1]))\n",
    "    if plyr == to_maximize: # max player\n",
    "        best = max(scores, key= lambda x: x[1])\n",
    "    else:\n",
    "        best = min(scores, key = lambda  x: x[1])\n",
    "    choice = next_actions[best[0]]\n",
    "    return choice, best[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = TicTacToe()\n",
    "g.add_o((2,2))\n",
    "g.add_o((0,0))\n",
    "g.add_x((0, 2))\n",
    "g.add_x((2,1))\n",
    "mov, _ = minmax(g, \"O\", \"O\")\n",
    "g.add_o(mov)\n",
    "g.add_x((2, 0))\n",
    "mov, _ = minmax(g, \"O\", \"O\")\n",
    "g.add_o(mov)\n",
    "print(g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "outputs": [],
   "source": [
    "class MinMaxPlayer:\n",
    "    def __init__(self, name, letter):\n",
    "        self._name = name\n",
    "        self._letter = letter\n",
    "\n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "\n",
    "    def move(self, game_inst: TicTacToe):\n",
    "        if self._letter == \"X\":\n",
    "            mv, _ = minmax(game_inst, \"X\", \"X\")\n",
    "            game_inst.add_x(mv)\n",
    "        else:\n",
    "            mv, _ = minmax(game_inst, \"O\", \"O\")\n",
    "            game_inst.add_o(mv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:24<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning Rate against Random: 0.0\n",
      "Drawing Rate against Random: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def benchmark():\n",
    "    winning = 0\n",
    "    drawing = 0\n",
    "    agent0 = Player(\"Agent0\", Qtable, \"X\")\n",
    "    agent1 = MinMaxPlayer(\"Agent1\", \"O\")\n",
    "    for i in tqdm(range(100)):\n",
    "        inst = TicTacToe()\n",
    "        player = 0\n",
    "        steps = 0\n",
    "        while inst.check() == 0 and steps < 9:\n",
    "            if player == 0:\n",
    "                agent0.move(inst)\n",
    "            else:\n",
    "                # if steps == 0:\n",
    "                #     rand_ind = random.randint(0,8)\n",
    "                #     inst.add_o(inst.next_moves()[rand_ind])\n",
    "                # else:\n",
    "                agent1.move(inst)\n",
    "            player = 1 - player\n",
    "            steps += 1\n",
    "        if inst.check() == 1:\n",
    "            winning += 1\n",
    "        elif inst.check() == 0:\n",
    "            drawing += 1\n",
    "    win_rate = winning * 100 / 100\n",
    "    draw_rate = drawing * 100 / 100\n",
    "    print(f\"Winning Rate against Random: {win_rate}\")\n",
    "    print(f\"Drawing Rate against Random: {draw_rate}\")\n",
    "\n",
    "benchmark()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
